{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review_id': 'wslW2Lu4NYylb1jEapAGsw', 'user_id': 'r1NUhdNmL6yU9Bn-Yx6FTw', 'business_id': '2aFiy99vNLklCx3T_tGS9A', 'stars': 5, 'date': '2011-04-29', 'text': 'Great service! Corey is very service oriented. Works fast and very effiecient with his time. Going to use him again real soon to do additional IT services. thanks Corey.', 'useful': 0, 'funny': 0, 'cool': 0, 'type': 'review'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#OPENING YELP REVIEWS DATASETS\n",
    "#read the data from disk and split into lines\n",
    "#we use .strip() to remove the final (empty) line\n",
    "with open(\"yelp_academic_dataset_review.json\",encoding='utf-8') as f:\n",
    "    reviews = f.read().strip().split(\"\\n\")\n",
    " \n",
    "#each line of the file is a separate JSON object\n",
    "reviews = [json.loads(review) for review in reviews] \n",
    "print(reviews[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each star category, we would like to get equal number of samples to build model. \n",
    "#So we define a function called 'getsample' to get 1000 datapoints from each star category.\n",
    "sample_review=[]\n",
    "sample_review2=[]\n",
    "def getsample(star):\n",
    "    for review in reviews:\n",
    "        if review['stars']==star:\n",
    "            sample_review.append(review)\n",
    "    random.seed(17)\n",
    "    sample=random.sample(sample_review, 1000)\n",
    "    sample_review2.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "getsample(1)\n",
    "getsample(2)\n",
    "getsample(3)\n",
    "getsample(4)\n",
    "getsample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer the sample datapoints into dataframe\n",
    "review=[]\n",
    "star=[]\n",
    "for i in sample_review2:\n",
    "    for j in i:\n",
    "        review.append(j['text'])\n",
    "        star.append(j['stars'])\n",
    "df={'text':review,'stars':star}\n",
    "sample_reviews=pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train and test data\n",
    "#We randomly select 80% of the data into train dataset and the rest 20% as test dataset.\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(17)\n",
    "train_reviews, test_reviews = train_test_split(sample_reviews, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1926</td>\n",
       "      <td>After this guy appearing on TV, I thought: \"Ne...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805</td>\n",
       "      <td>THIS PLACE IS CLOSED \\n(I passed by on 8/5/15)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1674</td>\n",
       "      <td>I have been eager to try Los Sombreros for som...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>Came here for the \"midnight\" launch of the PSV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2266</td>\n",
       "      <td>We were looking for something quick to do on T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>Burgers  &amp; Beers are great! If you go, ask for...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337</td>\n",
       "      <td>I put 1 star only because I have to put a star...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>Read reviews and had open mind. Didn't stay to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2191</td>\n",
       "      <td>3.5\\n\\nWent to the comedy show two nights ago....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2671</td>\n",
       "      <td>As a gay man, I came here to support one of my...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  stars\n",
       "1926  After this guy appearing on TV, I thought: \"Ne...      2\n",
       "805   THIS PLACE IS CLOSED \\n(I passed by on 8/5/15)...      1\n",
       "1674  I have been eager to try Los Sombreros for som...      2\n",
       "81    Came here for the \"midnight\" launch of the PSV...      1\n",
       "2266  We were looking for something quick to do on T...      1\n",
       "...                                                 ...    ...\n",
       "2800  Burgers  & Beers are great! If you go, ask for...      3\n",
       "1337  I put 1 star only because I have to put a star...      1\n",
       "406   Read reviews and had open mind. Didn't stay to...      1\n",
       "2191  3.5\\n\\nWent to the comedy show two nights ago....      3\n",
       "2671  As a gay man, I came here to support one of my...      2\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Collecting html.parser\n",
      "Requirement already satisfied: ply in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from html.parser) (3.11)\n",
      "Installing collected packages: html.parser\n",
      "Successfully installed html.parser\n",
      "Requirement already satisfied: pattern3 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: feedparser in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pattern3) (5.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pattern3) (4.8.0)\n",
      "Requirement already satisfied: cherrypy in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pattern3) (18.5.0)\n",
      "Requirement already satisfied: pdfminer3k in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pattern3) (1.3.1)\n",
      "Requirement already satisfied: simplejson in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pattern3) (3.17.0)\n",
      "Requirement already satisfied: docx in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pattern3) (0.2.4)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pattern3) (20200402)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from beautifulsoup4->pattern3) (1.9.3)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (7.2.0)\n",
      "Requirement already satisfied: jaraco.collections in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (3.0.0)\n",
      "Requirement already satisfied: zc.lockfile in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (2.0)\n",
      "Requirement already satisfied: cheroot>=8.2.1 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (8.3.0)\n",
      "Requirement already satisfied: portend>=2.1.1 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (2.6)\n",
      "Requirement already satisfied: pywin32; sys_platform == \"win32\" in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cherrypy->pattern3) (223)\n",
      "Requirement already satisfied: ply>=3.4 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pdfminer3k->pattern3) (3.11)\n",
      "Requirement already satisfied: pytest>=2.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pdfminer3k->pattern3) (5.2.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from docx->pattern3) (4.4.1)\n",
      "Requirement already satisfied: Pillow>=2.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from docx->pattern3) (6.2.0)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (3.9.7)\n",
      "Requirement already satisfied: chardet; python_version > \"3.0\" in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (3.0.4)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern3) (2.1.0)\n",
      "Requirement already satisfied: jaraco.classes in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from jaraco.collections->cherrypy->pattern3) (3.1.0)\n",
      "Requirement already satisfied: jaraco.text in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from jaraco.collections->cherrypy->pattern3) (3.2.0)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from jaraco.collections->cherrypy->pattern3) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from zc.lockfile->cherrypy->pattern3) (41.4.0)\n",
      "Requirement already satisfied: jaraco.functools in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern3) (3.0.0)\n",
      "Requirement already satisfied: tempora>=1.8 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from portend>=2.1.1->cherrypy->pattern3) (3.0.0)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (1.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (19.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (19.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.23)\n",
      "Requirement already satisfied: colorama in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k->pattern3) (0.4.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern3) (2019.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from packaging->pytest>=2.0->pdfminer3k->pattern3) (2.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest>=2.0->pdfminer3k->pattern3) (0.6.0)\n",
      "Requirement already satisfied: pyLDAvis in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.10.3)\n",
      "Requirement already satisfied: numexpr in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.16.5)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.3.1)\n",
      "Requirement already satisfied: future in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.25.1)\n",
      "Requirement already satisfied: funcy in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.14)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: pytest in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.33.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.0)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (19.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (19.2.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (7.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.23)\n",
      "Requirement already satisfied: colorama in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.17.0->pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from packaging->pytest->pyLDAvis) (2.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\17801\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest->pyLDAvis) (0.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\17801\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\17801\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\17801\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\17801\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  ['<', 'p', '>', 'The', 'circus', 'dog', 'in', 'a', 'plissé', 'skirt', 'jumped', 'over', 'Python', 'who', 'was', \"n't\", 'that', 'large', ',', 'just', '3', 'feet', 'long.', '<', '/p', '>']\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plissé skirt jumped over Python who was not that large, just 3 feet long.</p>\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  [('<', 'a'), ('p', 'n'), ('>', 'v'), ('the', None), ('circus', 'n'), ('dog', 'n'), ('in', None), ('a', None), ('plissé', 'n'), ('skirt', 'n'), ('jumped', 'v'), ('over', None), ('python', 'n'), ('who', None), ('was', 'v'), (\"n't\", 'r'), ('that', None), ('large', 'a'), (',', None), ('just', 'r'), ('3', None), ('feet', 'n'), ('long.', 'a'), ('<', 'n'), ('/p', 'n'), ('>', 'n')]\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > the circus dog in a plissé skirt jump over python who be n't that large , just 3 foot long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:    p   The circus dog in a plissé skirt jumped over Python who was n t that large   just 3 feet long     p  \n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  < p > The circus dog plissé skirt jumped Python n't large , 3 feet long. < /p >\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  p The circus dog in a plissé skirt jumped over Python who was n't that large just feet long. /p\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.\n",
      "Original:   <p>The circus dog in a plissé skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n",
      "Processed:  <p>The circus dog in a plisse skirt jumped over Python who wasn't that large, just 3 feet long.</p>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "#!{sys.executable} -m pip install nltk\n",
    "import nltk\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "#text normalization function\n",
    "%run ./Text_Normalization_Function.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = np.array(test_reviews['text'])\n",
    "test_polarity = np.array(test_reviews['stars'])\n",
    "\n",
    "train_review = np.array(train_reviews['text'])\n",
    "train_polarity = np.array(train_reviews['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_test_reviews = normalize_corpus(test_review)\n",
    "normalized_train_reviews = normalize_corpus(train_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2)) \n",
    "feature_matrix_TRAIN = vectorizer.fit_transform(normalized_train_reviews).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_TRAIN_names = vectorizer.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00am</th>\n",
       "      <th>00am husband</th>\n",
       "      <th>00am starve</th>\n",
       "      <th>00ish</th>\n",
       "      <th>00ish kid</th>\n",
       "      <th>00p</th>\n",
       "      <th>00p customer</th>\n",
       "      <th>00pm</th>\n",
       "      <th>00pm apologize</th>\n",
       "      <th>00pm friday</th>\n",
       "      <th>...</th>\n",
       "      <th>zwar</th>\n",
       "      <th>zwar durch</th>\n",
       "      <th>zwar gar</th>\n",
       "      <th>zwar nicht</th>\n",
       "      <th>zwei</th>\n",
       "      <th>zwei bier</th>\n",
       "      <th>zweite</th>\n",
       "      <th>zweite chance</th>\n",
       "      <th>zwischendurch</th>\n",
       "      <th>zwischendurch mit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00am  00am husband  00am starve  00ish  00ish kid  00p  00p customer  00pm  \\\n",
       "0   0.0           0.0          0.0    0.0        0.0  0.0           0.0   0.0   \n",
       "1   0.0           0.0          0.0    0.0        0.0  0.0           0.0   0.0   \n",
       "2   0.0           0.0          0.0    0.0        0.0  0.0           0.0   0.0   \n",
       "3   0.0           0.0          0.0    0.0        0.0  0.0           0.0   0.0   \n",
       "4   0.0           0.0          0.0    0.0        0.0  0.0           0.0   0.0   \n",
       "\n",
       "   00pm apologize  00pm friday  ...  zwar  zwar durch  zwar gar  zwar nicht  \\\n",
       "0             0.0          0.0  ...   0.0         0.0       0.0         0.0   \n",
       "1             0.0          0.0  ...   0.0         0.0       0.0         0.0   \n",
       "2             0.0          0.0  ...   0.0         0.0       0.0         0.0   \n",
       "3             0.0          0.0  ...   0.0         0.0       0.0         0.0   \n",
       "4             0.0          0.0  ...   0.0         0.0       0.0         0.0   \n",
       "\n",
       "   zwei  zwei bier  zweite  zweite chance  zwischendurch  zwischendurch mit  \n",
       "0   0.0        0.0     0.0            0.0            0.0                0.0  \n",
       "1   0.0        0.0     0.0            0.0            0.0                0.0  \n",
       "2   0.0        0.0     0.0            0.0            0.0                0.0  \n",
       "3   0.0        0.0     0.0            0.0            0.0                0.0  \n",
       "4   0.0        0.0     0.0            0.0            0.0                0.0  \n",
       "\n",
       "[5 rows x 160280 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_TRAIN_table = pd.DataFrame(data = feature_matrix_TRAIN.todense(),columns = feature_matrix_TRAIN_names)\n",
    "feature_matrix_TRAIN_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_TEST = vectorizer.transform(normalized_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Naive Bayes Classifer to build a multi-class model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NBmodel = MultinomialNB()\n",
    "NBmodel.fit(feature_matrix_TRAIN, train_polarity) \n",
    "predict1 = NBmodel.predict_proba(feature_matrix_TEST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76529458, 0.10178316, 0.0674495 , 0.05865571, 0.00681704],\n",
       "       [0.512365  , 0.14271396, 0.08763701, 0.23441276, 0.02287127],\n",
       "       [0.63921094, 0.13355014, 0.11128971, 0.08392706, 0.03202215],\n",
       "       ...,\n",
       "       [0.82274312, 0.07041189, 0.06150278, 0.03848823, 0.00685399],\n",
       "       [0.87104641, 0.06502773, 0.03385891, 0.02427398, 0.00579296],\n",
       "       [0.89081724, 0.07083506, 0.02319493, 0.01282154, 0.00233123]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_bayes=[]\n",
    "for i in range(len(predict1)):\n",
    "    predict_list=predict1[i].tolist()\n",
    "    star=predict_list.index(max(predict_list[0:4]))+1\n",
    "    predict_bayes.append(star)\n",
    "#print('Accuracy rate:', np.round(metrics.accuracy_score(test_polarity, predict_bayes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer multi-class to 2 class(positive & negative)\n",
    "def startocategory(datalist):\n",
    "    category=[]\n",
    "    for i in datalist:\n",
    "        if i>3:\n",
    "            category.append(1)\n",
    "        else:\n",
    "            category.append(0)\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=startocategory(test_polarity)\n",
    "predict=startocategory(predict_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.804\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy rate:', np.round(metrics.accuracy_score(test, predict), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
